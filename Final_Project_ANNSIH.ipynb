{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, GRU, Dense, Dropout, MultiHeadAttention, Add, LayerNormalization, GlobalAveragePooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "SyS_vfzYwZa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "site_files = [\"site_1_train_data.csv\", \"site_2_train_data.csv\", \"site_3_train_data.csv\"]\n",
        "\n",
        "dfs = {}\n",
        "train_dfs = {}\n",
        "test_dfs = {}\n",
        "scaler_xs = {}\n",
        "scaler_ys = {}\n",
        "X_train_seqs = {}\n",
        "y_train_seqs = {}\n",
        "X_test_seqs = {}\n",
        "y_test_seqs = {}\n",
        "results = {}\n",
        "time_steps = 72"
      ],
      "metadata": {
        "id": "CqZiKayAtk2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in site_files:\n",
        "    df = pd.read_csv(file)\n",
        "    dfs[file] = df.copy()\n",
        "    print(file, \"initial shape:\", df.shape)"
      ],
      "metadata": {
        "id": "QeL78vX2Il2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f760475-430e-4f51-c542-d814aedc67f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "site_1_train_data.csv initial shape: (25081, 16)\n",
            "site_2_train_data.csv initial shape: (25969, 16)\n",
            "site_3_train_data.csv initial shape: (21913, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_cols = ['NO2_satellite', 'HCHO_satellite', 'ratio_satellite']\n",
        "for file, df in dfs.items():\n",
        "    for col in drop_cols:\n",
        "        if col in df.columns:\n",
        "            df.drop(columns=col, inplace=True)\n",
        "    dfs[file] = df\n",
        "    print(file, \"after dropping satellite cols:\", df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnLDKLiOIrc9",
        "outputId": "eb3743a9-5b0a-482b-a87c-5927a9343b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "site_1_train_data.csv after dropping satellite cols: (25081, 13)\n",
            "site_2_train_data.csv after dropping satellite cols: (25969, 13)\n",
            "site_3_train_data.csv after dropping satellite cols: (21913, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file, df in dfs.items():\n",
        "    df['datetime'] = pd.to_datetime(df[['year', 'month', 'day', 'hour']])\n",
        "    df = df.sort_values('datetime').reset_index(drop=True)\n",
        "    dfs[file] = df\n",
        "    print(file, \"after datetime sort:\", df.shape)"
      ],
      "metadata": {
        "id": "MDZQDLb2Ivxs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "853c424b-aca7-448f-f55d-4d8ab4216410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "site_1_train_data.csv after datetime sort: (25081, 14)\n",
            "site_2_train_data.csv after datetime sort: (25969, 14)\n",
            "site_3_train_data.csv after datetime sort: (21913, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file, df in dfs.items():\n",
        "    df.interpolate(method='linear', limit_direction='both', inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "    dfs[file] = df\n",
        "    print(file, \"after interpolation & dropna:\", df.shape)"
      ],
      "metadata": {
        "id": "2c_uOxzrIy4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb526424-4ff5-4959-c0b2-9afbd23900c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "site_1_train_data.csv after interpolation & dropna: (25081, 14)\n",
            "site_2_train_data.csv after interpolation & dropna: (25969, 14)\n",
            "site_3_train_data.csv after interpolation & dropna: (21913, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file, df in dfs.items():\n",
        "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
        "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
        "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "    df['O3_diff'] = df['O3_target'] - df['O3_target'].shift(1)\n",
        "    df['NO2_diff'] = df['NO2_target'] - df['NO2_target'].shift(1)\n",
        "    df.fillna(0, inplace=True)\n",
        "    dfs[file] = df"
      ],
      "metadata": {
        "id": "DEVYmISoI0Ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file, df in dfs.items():\n",
        "    for pollutant in ['O3_target', 'NO2_target']:\n",
        "        for lag in range(1, 73):\n",
        "            df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
        "    df.dropna(inplace=True)\n",
        "    dfs[file] = df"
      ],
      "metadata": {
        "id": "oG_wZj8zI3dk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "688885a9-245f-4d21-e30a-2893c0856657",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n",
            "/tmp/ipython-input-1133038121.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{pollutant}_lag_{lag}'] = df[pollutant].shift(lag)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_steps = 72\n",
        "\n",
        "for file, df in dfs.items():\n",
        "    input_features = [\n",
        "        'O3_forecast', 'NO2_forecast', 'T_forecast', 'q_forecast',\n",
        "        'u_forecast', 'v_forecast', 'w_forecast',\n",
        "        'hour_sin', 'hour_cos', 'month_sin', 'month_cos',\n",
        "        'O3_diff', 'NO2_diff'\n",
        "    ]\n",
        "    lag_features = [col for col in df.columns if '_lag_' in col]\n",
        "    input_features.extend(lag_features)\n",
        "    target_features = ['O3_target', 'NO2_target']\n",
        "\n",
        "    # Split train/test\n",
        "    train_df, test_df = train_test_split(df, test_size=0.25, shuffle=False)\n",
        "    train_dfs[file] = train_df\n",
        "    test_dfs[file] = test_df\n",
        "\n",
        "    # Input scaler (one per site)\n",
        "    scaler_x = StandardScaler()\n",
        "    X_train = scaler_x.fit_transform(train_df[input_features])\n",
        "    X_test = scaler_x.transform(test_df[input_features])\n",
        "    scaler_xs[file] = scaler_x\n",
        "\n",
        "    # Create sequences for X\n",
        "    Xs_train, Xs_test = [], []\n",
        "    for i in range(len(X_train) - time_steps):\n",
        "        Xs_train.append(X_train[i:(i + time_steps)])\n",
        "    for i in range(len(X_test) - time_steps):\n",
        "        Xs_test.append(X_test[i:(i + time_steps)])\n",
        "\n",
        "    X_train_seq = np.array(Xs_train)\n",
        "    X_test_seq = np.array(Xs_test)\n",
        "    X_train_seqs[file] = X_train_seq\n",
        "    X_test_seqs[file] = X_test_seq\n",
        "\n",
        "    # Target scalers per pollutant (O3, NO2)\n",
        "    for pollutant in target_features:\n",
        "        scaler_y = StandardScaler()\n",
        "        y_train_full = scaler_y.fit_transform(train_df[[pollutant]])\n",
        "        y_test_full = scaler_y.transform(test_df[[pollutant]])\n",
        "\n",
        "        ys_train, ys_test = [], []\n",
        "        for i in range(len(y_train_full) - time_steps):\n",
        "            ys_train.append(y_train_full[i + time_steps])\n",
        "        for i in range(len(y_test_full) - time_steps):\n",
        "            ys_test.append(y_test_full[i + time_steps])\n",
        "\n",
        "        y_train_seq = np.array(ys_train)\n",
        "        y_test_seq = np.array(ys_test)\n",
        "\n",
        "        # Save the target-specific scaler\n",
        "        scaler_ys[(file, pollutant)] = scaler_y\n",
        "        y_train_seqs[(file, pollutant)] = y_train_seq\n",
        "        y_test_seqs[(file, pollutant)] = y_test_seq\n",
        "\n",
        "    print(file,\n",
        "          \"Train seq shape:\", X_train_seq.shape,\n",
        "          \"Test seq shape:\", X_test_seq.shape)\n"
      ],
      "metadata": {
        "id": "rQKIY-rQI7Lh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbe504e5-919b-416a-e8aa-1b2122aa9731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "site_1_train_data.csv Train seq shape: (18684, 72, 157) Test seq shape: (6181, 72, 157)\n",
            "site_2_train_data.csv Train seq shape: (19350, 72, 157) Test seq shape: (6403, 72, 157)\n",
            "site_3_train_data.csv Train seq shape: (16308, 72, 157) Test seq shape: (5389, 72, 157)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "\n",
        "os.makedirs(\"saved_scalers\", exist_ok=True)\n",
        "\n",
        "for file, x_scaler in scaler_xs.items():\n",
        "    site = file.replace(\"_train_data.csv\", \"\")\n",
        "    x_path = f\"saved_scalers/{site}_X_scaler.pkl\"\n",
        "    joblib.dump(x_scaler, x_path)\n",
        "    print(\"Saved X-scaler:\", x_path)\n",
        "\n",
        "for key, y_scaler in scaler_ys.items():\n",
        "    if isinstance(key, tuple):\n",
        "        file, pollutant = key\n",
        "        site = file.replace(\"_train_data.csv\", \"\")\n",
        "        poll_short = pollutant.replace(\"_target\", \"\")\n",
        "        y_path = f\"saved_scalers/{site}_{poll_short}_Y_scaler.pkl\"\n",
        "        joblib.dump(y_scaler, y_path)\n",
        "        print(f\"Saved Y-scaler for {site} - {poll_short}: {y_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUz9Tl1XReSE",
        "outputId": "dcb3fe18-b0ce-49c2-c6d4-4fcffa3fb795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved X-scaler: saved_scalers/site_1_X_scaler.pkl\n",
            "Saved X-scaler: saved_scalers/site_2_X_scaler.pkl\n",
            "Saved X-scaler: saved_scalers/site_3_X_scaler.pkl\n",
            "Saved Y-scaler for site_1 - O3: saved_scalers/site_1_O3_Y_scaler.pkl\n",
            "Saved Y-scaler for site_1 - NO2: saved_scalers/site_1_NO2_Y_scaler.pkl\n",
            "Saved Y-scaler for site_2 - O3: saved_scalers/site_2_O3_Y_scaler.pkl\n",
            "Saved Y-scaler for site_2 - NO2: saved_scalers/site_2_NO2_Y_scaler.pkl\n",
            "Saved Y-scaler for site_3 - O3: saved_scalers/site_3_O3_Y_scaler.pkl\n",
            "Saved Y-scaler for site_3 - NO2: saved_scalers/site_3_NO2_Y_scaler.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"saved_scalers_zip\", 'zip', \"saved_scalers\")\n",
        "print(\"Zipped  saved_scalers_zip.zip\")\n"
      ],
      "metadata": {
        "id": "J3Cuer74TWnp",
        "outputId": "a64006d4-4d67-48ee-a0ce-b47806b1ee68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zipped  saved_scalers_zip.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, file in enumerate(site_files, start=1):\n",
        "    X_train_seq = X_train_seqs[file]\n",
        "    X_test_seq = X_test_seqs[file]\n",
        "    train_df = train_dfs[file]\n",
        "    test_df = test_dfs[file]\n",
        "\n",
        "    for pollutant in ['O3_target', 'NO2_target']:\n",
        "        print(f\"\\n\\n==================== {file} - {pollutant} ====================\")\n",
        "\n",
        "        scaler_y = StandardScaler()\n",
        "        scaler_ys[(file, pollutant)] = scaler_y\n",
        "        y_train_full = scaler_y.fit_transform(train_df[[pollutant]])\n",
        "        y_test_full = scaler_y.transform(test_df[[pollutant]])\n",
        "\n",
        "        ys_train = []\n",
        "        for i in range(len(y_train_full) - time_steps):\n",
        "            ys_train.append(y_train_full[i + time_steps])\n",
        "        y_train_seq = np.array(ys_train)\n",
        "\n",
        "        ys_test = []\n",
        "        for i in range(len(y_test_full) - time_steps):\n",
        "            ys_test.append(y_test_full[i + time_steps])\n",
        "        y_test_seq = np.array(ys_test)\n",
        "\n",
        "        y_train_seqs[(file, pollutant)] = y_train_seq\n",
        "        y_test_seqs[(file, pollutant)] = y_test_seq\n",
        "\n",
        "        callbacks = [\n",
        "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
        "        ]\n",
        "\n",
        "        inputs = Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2]))\n",
        "        x = LSTM(128, return_sequences=True)(inputs)\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = LSTM(64)(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = Dense(32, activation='relu')(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        outputs = Dense(1)(x)\n",
        "        lstm_model = Model(inputs, outputs)\n",
        "        lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "        print(\"Training LSTM...\")\n",
        "        lstm_model.fit(X_train_seq, y_train_seq, validation_data=(X_test_seq, y_test_seq), epochs=100, batch_size=64, callbacks=callbacks, verbose=2)\n",
        "        y_pred_lstm = lstm_model.predict(X_test_seq)\n",
        "\n",
        "        inputs = Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2]))\n",
        "        x = GRU(128, return_sequences=True)(inputs)\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = GRU(64)(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = Dense(32, activation='relu')(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        outputs = Dense(1)(x)\n",
        "        gru_model = Model(inputs, outputs)\n",
        "        gru_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "        print(\"Training GRU...\")\n",
        "        gru_model.fit(X_train_seq, y_train_seq, validation_data=(X_test_seq, y_test_seq), epochs=100, batch_size=64, callbacks=callbacks, verbose=2)\n",
        "        y_pred_gru = gru_model.predict(X_test_seq)\n",
        "\n",
        "        inputs = Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2]))\n",
        "        attn = MultiHeadAttention(num_heads=4, key_dim=64)(inputs, inputs)\n",
        "        attn = Dropout(0.2)(attn)\n",
        "        x = Add()([inputs, attn])\n",
        "        x = LayerNormalization(epsilon=1e-6)(x)\n",
        "        ffn = Dense(128, activation='relu')(x)\n",
        "        ffn = Dropout(0.2)(ffn)\n",
        "        ffn = Dense(X_train_seq.shape[2])(ffn)\n",
        "        x = Add()([x, ffn])\n",
        "        x = LayerNormalization(epsilon=1e-6)(x)\n",
        "        x = GlobalAveragePooling1D()(x)\n",
        "        x = Dense(32, activation='relu')(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        outputs = Dense(1)(x)\n",
        "        trans_model = Model(inputs, outputs)\n",
        "        trans_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "        print(\"Training Transformer...\")\n",
        "        trans_model.fit(X_train_seq, y_train_seq, validation_data=(X_test_seq, y_test_seq), epochs=100, batch_size=64, callbacks=callbacks, verbose=2)\n",
        "        y_pred_trans = trans_model.predict(X_test_seq)\n",
        "\n",
        "        y_pred_ensemble_scaled = 0.4 * y_pred_gru + 0.4 * y_pred_lstm + 0.2 * y_pred_trans\n",
        "\n",
        "        y_test_inv = scaler_y.inverse_transform(y_test_seq.reshape(-1, 1)).reshape(-1)\n",
        "        y_pred_inv = scaler_y.inverse_transform(y_pred_ensemble_scaled.reshape(-1, 1)).reshape(-1)\n",
        "\n",
        "        results[(file, pollutant, 'Ensemble')] = {\"y_true\": y_test_inv, \"y_pred\": y_pred_inv}\n",
        "\n",
        "        import os\n",
        "        site_name = file.replace(\"_train_data.csv\",\"\")   # e.g. \"site_1\"\n",
        "        poll_short = pollutant.replace(\"_target\",\"\")     # e.g. \"O3\" or \"NO2\"\n",
        "        save_dir = os.path.join(\"saved_models\", site_name)\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        lstm_path = os.path.join(save_dir, f\"{site_name}_{poll_short}_LSTM.keras\")\n",
        "        gru_path  = os.path.join(save_dir, f\"{site_name}_{poll_short}_GRU.keras\")\n",
        "        trans_path= os.path.join(save_dir, f\"{site_name}_{poll_short}_TRANS.keras\")\n",
        "\n",
        "        lstm_model.save(lstm_path)\n",
        "        gru_model.save(gru_path)\n",
        "        trans_model.save(trans_path)\n",
        "\n",
        "        print(f\"\\n Saved: {lstm_path}\")\n",
        "        print(f\" Saved: {gru_path}\")\n",
        "        print(f\" Saved: {trans_path}\")\n",
        "        # --- end save ---"
      ],
      "metadata": {
        "id": "xuL5pBhEI-FP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "1f456b20-180f-476f-8858-0e6d7fe455b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "==================== site_1_train_data.csv - O3_target ====================\n",
            "Training LSTM...\n",
            "Epoch 1/100\n",
            "292/292 - 82s - 281ms/step - loss: 0.2979 - val_loss: 0.0893 - learning_rate: 1.0000e-03\n",
            "Epoch 2/100\n",
            "292/292 - 80s - 273ms/step - loss: 0.1738 - val_loss: 0.0793 - learning_rate: 1.0000e-03\n",
            "Epoch 3/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3784556774.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mlstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training LSTM...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mlstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0my_pred_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_rows = []\n",
        "\n",
        "for (file, pollutant, model_name), data in results.items():\n",
        "    y_true_inv = data[\"y_true\"]\n",
        "    y_pred_inv = data[\"y_pred\"]\n",
        "    site = file.split(\"_train_data.csv\")[0]\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_true_inv, y_pred_inv))\n",
        "    mae = mean_absolute_error(y_true_inv, y_pred_inv)\n",
        "    r2 = r2_score(y_true_inv, y_pred_inv)\n",
        "    obs_mean = y_true_inv.mean()\n",
        "    numerator = np.sum((y_pred_inv - y_true_inv) ** 2)\n",
        "    denominator = np.sum((np.abs(y_pred_inv - y_true_inv) + np.abs(y_true_inv - obs_mean)) ** 2)\n",
        "    ria = 1 - (numerator / denominator) if denominator != 0 else np.nan\n",
        "\n",
        "    summary_rows.append({\n",
        "        \"Site\": site,\n",
        "        \"Model\": model_name,\n",
        "        \"Target\": pollutant,\n",
        "        \"RMSE\": rmse,\n",
        "        \"MAE\": mae,\n",
        "        \"R2\": r2,\n",
        "        \"RIA\": ria\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "print(\"\\n PERFORMANCE SUMMARY (All Sites & Models) \")\n",
        "print(summary_df.to_string(index=False))\n",
        "\n",
        "avg_summary = summary_df.groupby([\"Site\", \"Model\"])[[\"RMSE\",\"MAE\",\"R2\",\"RIA\"]].mean().reset_index()\n",
        "print(\"\\nAVERAGE PERFORMANCE PER SITE\")\n",
        "print(avg_summary.to_string(index=False))\n",
        "\n",
        "best_per_site = avg_summary.loc[avg_summary.groupby(\"Site\")[\"R2\"].idxmax()]\n",
        "print(\"\\n BEST MODEL PER SITE (By R) \")\n",
        "print(best_per_site.to_string(index=False))\n",
        "\n",
        "overall_best = avg_summary.groupby(\"Model\")[[\"R2\",\"RIA\"]].mean().reset_index().sort_values(by=\"R2\", ascending=False).head(1)\n",
        "print(\"\\n OVERALL BEST MODEL\")\n",
        "print(overall_best.to_string(index=False))"
      ],
      "metadata": {
        "id": "gkjD6VahJBV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"saved_models\", 'zip', \"saved_models\")"
      ],
      "metadata": {
        "id": "0FZGsvMNgDRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"saved_models.zip\")\n"
      ],
      "metadata": {
        "id": "iLk1sH-dgHra"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}